import json
from pathlib import Path

import pandas as pd
import streamlit as st
from joblib import load
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from src.obesity_tc.make_dataset import preprocessar_base

BASE_DIR = Path(__file__).resolve().parents[1]
MODEL_PATH = BASE_DIR / "models/modelo_obesidade.joblib"
DATA_PATH = BASE_DIR / "data/raw/Obesity.csv"
METRICS_PATH = BASE_DIR / "reports/metrics.json"
REPORT_PATH = BASE_DIR / "reports/classification_report.txt"

MAPA_NIVEL_OBESIDADE = {
    "Insufficient_Weight": "Peso insuficiente",
    "Normal_Weight": "Peso normal",
    "Overweight_Level_I": "Sobrepeso n√≠vel I",
    "Overweight_Level_II": "Sobrepeso n√≠vel II",
    "Obesity_Type_I": "Obesidade tipo I",
    "Obesity_Type_II": "Obesidade tipo II",
    "Obesity_Type_III": "Obesidade tipo III",
}


@st.cache_resource
def ler_modelo():
    if not MODEL_PATH.exists():
        raise FileNotFoundError(
            "Modelo n√£o encontrado. Treine com: "
            "python -m src.obesity_tc.train --data data/raw/Obesity.csv --target Obesity"
        )
    return load(MODEL_PATH)


@st.cache_data
def ler_base() -> pd.DataFrame:
    if not DATA_PATH.exists():
        raise FileNotFoundError("Base de dados n√£o encontrada em data/raw/Obesity.csv.")
    df_raw = pd.read_csv(DATA_PATH)
    return preprocessar_base(df_raw, coluna_alvo="Obesity")


def ler_metricas() -> dict:
    if not METRICS_PATH.exists():
        return {}
    try:
        return json.loads(METRICS_PATH.read_text(encoding="utf-8"))
    except json.JSONDecodeError:
        return {}


def ler_relatorio() -> str:
    if not REPORT_PATH.exists():
        return ""
    return REPORT_PATH.read_text(encoding="utf-8")


st.title("M√©tricas e documenta√ß√£o do modelo")

st.markdown(
    """
### üß≠ Predi√ß√£o de n√≠vel de obesidade
Bem-vindo √† documenta√ß√£o do projeto Tech Challenge - Fase 4. Este trabalho foi
desenvolvido para apoiar a avalia√ß√£o do n√≠vel de obesidade a partir de dados de perfil
e h√°bitos de vida.

### üéØ Objetivo do projeto
Construir um modelo de Machine Learning capaz de **classificar o n√≠vel de obesidade** de um
indiv√≠duo com base em dados demogr√°ficos, h√°bitos alimentares e estilo de vida. O resultado
serve como apoio √† triagem e n√£o substitui a avalia√ß√£o cl√≠nica.

### üß© A solu√ß√£o
- **An√°lise explorat√≥ria:** entendimento da distribui√ß√£o das classes e do perfil dos dados.
- **Engenharia de atributos:** preparo e padroniza√ß√£o do dataset, incluindo c√°lculo de IMC.
- **Modelagem:** Random Forest com balanceamento das classes para reduzir vieses.
- **Aplica√ß√£o web:** interface em Streamlit para predi√ß√µes individuais.

### üìä M√©tricas usadas
- ‚úÖ **Acur√°cia:** propor√ß√£o total de acertos no conjunto avaliado.
- üéØ **Precis√£o:** entre as previs√µes de cada classe, quantas estavam corretas.
- üîé **Recall (sensibilidade):** entre os casos reais de uma classe, quantos o modelo encontrou.
- üß™ **F1-score:** equil√≠brio entre precis√£o e recall, √∫til quando h√° desbalanceamento.
- üì¶ **Support:** n√∫mero de amostras por classe no conjunto de teste.
- üß≠ **Matriz de confus√£o:** vis√£o detalhada de acertos e erros entre classes.
- ‚öñÔ∏è **M√©dias macro e ponderada:** macro d√° o mesmo peso para cada classe, a ponderada
  considera o volume de amostras (support).

### üèÅ Resultados-chave
As m√©tricas abaixo s√£o geradas a partir do **modelo treinado** e dos **dados atuais**.
Use o relat√≥rio por classe para comparar precis√£o, recall e f1-score.
"""
)

metricas = ler_metricas()
relatorio = ler_relatorio()

if metricas:
    st.subheader("Resumo da √∫ltima execu√ß√£o")
    col1, col2, col3 = st.columns(3)
    col1.metric("Acur√°cia", f"{float(metricas.get('acuracia', 0)):.4f}")
    col2.metric("Treino", int(metricas.get("n_treino", 0)))
    col3.metric("Teste", int(metricas.get("n_teste", 0)))

    matriz = metricas.get("matriz_confusao")
    if matriz:
        st.subheader("Matriz de confus√£o (treino/teste)")
        classes = metricas.get("classes") or metricas.get("classes_original")
        if classes:
            st.dataframe(pd.DataFrame(matriz, index=classes, columns=classes))
        else:
            st.dataframe(pd.DataFrame(matriz))
else:
    st.info(
        "Relat√≥rios n√£o encontrados. Execute o notebook "
        "`notebooks/modelo_obesidade_tc.ipynb` para gerar as m√©tricas."
    )

if relatorio:
    st.subheader("Relat√≥rio de classifica√ß√£o (treino/teste)")
    st.code(relatorio)

st.divider()
st.subheader("M√©tricas r√°pidas com a base atual")

if st.button("Calcular m√©tricas agora"):
    try:
        bundle = ler_modelo()
    except FileNotFoundError as exc:
        st.error(str(exc))
        st.stop()

    try:
        df = ler_base()
    except FileNotFoundError as exc:
        st.error(str(exc))
        st.stop()

    if "Obesity_level" not in df.columns:
        st.error("A base n√£o possui a coluna Obesity_level para avalia√ß√£o.")
        st.stop()

    y_true = df["Obesity_level"]
    X = df.drop(columns=["Obesity_level"])

    pred = bundle["pipeline"].predict(X)
    acc = accuracy_score(y_true, pred)
    st.metric("Acur√°cia (base atual)", f"{acc:.4f}")

    classes_ordenadas = sorted(y_true.unique().tolist())
    classes_pt = [MAPA_NIVEL_OBESIDADE.get(c, c) for c in classes_ordenadas]
    st.subheader("Relat√≥rio de classifica√ß√£o (base atual)")
    st.code(
        classification_report(
            y_true,
            pred,
            labels=classes_ordenadas,
            target_names=classes_pt,
            digits=4,
        )
    )

    st.subheader("Matriz de confus√£o (base atual)")
    st.dataframe(confusion_matrix(y_true, pred, labels=classes_ordenadas))
